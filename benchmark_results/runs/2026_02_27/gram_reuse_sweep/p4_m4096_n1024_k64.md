# Gram Reuse-Precond Benchmark

## Config
- device: `cuda`
- dtype: `torch.float32`
- p: `4`
- G shape: `4096x1024`
- M shape: `1024x64`
- trials: `10`
- timing_reps: `3`
- warmup_reps: `1`
- gram_mode: `col-norm`
- precond_mode: `jacobi`
- l_target: `0.05`

## Results
- A (`reuse_precond=False`): `8.047 ms`
- B (`reuse_precond=True`): `4.657 ms`
- speedup (A/B): `1.728x`
- output rel diff (A vs B): `0.000e+00`
