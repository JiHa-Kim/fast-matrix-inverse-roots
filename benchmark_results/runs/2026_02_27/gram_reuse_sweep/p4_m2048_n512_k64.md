# Gram Reuse-Precond Benchmark

## Config
- device: `cuda`
- dtype: `torch.float32`
- p: `4`
- G shape: `2048x512`
- M shape: `512x64`
- trials: `10`
- timing_reps: `3`
- warmup_reps: `1`
- gram_mode: `col-norm`
- precond_mode: `jacobi`
- l_target: `0.05`

## Results
- A (`reuse_precond=False`): `2.996 ms`
- B (`reuse_precond=True`): `1.158 ms`
- speedup (A/B): `2.587x`
- output rel diff (A vs B): `0.000e+00`
